{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11836644,"sourceType":"datasetVersion","datasetId":7436518}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hyvULYwNwl1d","outputId":"336809aa-4a72-4905-afde-86d58b0a07ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"execution_count":2},{"cell_type":"code","source":"import os\nos.chdir(\"drive/MyDrive/DA6401/DA6401_A3/\")\n","metadata":{"id":"nmo0Xz8nMfWD"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\ntrain_file = \"/kaggle/input/lexicons/ta.translit.sampled.train.tsv\"\ndev_file = \"/kaggle/input/lexicons/ta.translit.sampled.dev.tsv\"\ntest_file = \"/kaggle/input/lexicons/ta.translit.sampled.test.tsv\"\n\ntrain_data = pd.read_csv (train_file, header=None, sep='\\t')\ndev_data = pd.read_csv (dev_file, header=None, sep='\\t')\ntest_data = pd.read_csv (test_file, header=None, sep='\\t')\n","metadata":{"id":"lLePotfbN6Cv","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:30:38.797550Z","iopub.execute_input":"2025-05-19T16:30:38.797801Z","iopub.status.idle":"2025-05-19T16:30:40.563035Z","shell.execute_reply.started":"2025-05-19T16:30:38.797779Z","shell.execute_reply":"2025-05-19T16:30:40.562299Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"test_data","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"RBIECFF7NepN","outputId":"5d580212-53f5-4f86-fb9d-3275b62953da","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:30:40.564716Z","iopub.execute_input":"2025-05-19T16:30:40.564994Z","iopub.status.idle":"2025-05-19T16:30:40.606914Z","shell.execute_reply.started":"2025-05-19T16:30:40.564972Z","shell.execute_reply":"2025-05-19T16:30:40.605928Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"            0        1  2\n0     ஃபார்ம்    faarm  1\n1     ஃபார்ம்     farm  2\n2     ஃபார்ம்     form  1\n3     ஃபார்ம்   hpaarm  1\n4       ஃபேஸ்     face  3\n...       ...      ... ..\n6859   ஹைட்ரோ  haidroa  2\n6860   ஹைட்ரோ  haitrao  1\n6861   ஹைட்ரோ    hydro  3\n6862    ஹைதர்  haithar  2\n6863    ஹைதர்    hyder  3\n\n[6864 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ஃபார்ம்</td>\n      <td>faarm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ஃபார்ம்</td>\n      <td>farm</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ஃபார்ம்</td>\n      <td>form</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ஃபார்ம்</td>\n      <td>hpaarm</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ஃபேஸ்</td>\n      <td>face</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6859</th>\n      <td>ஹைட்ரோ</td>\n      <td>haidroa</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6860</th>\n      <td>ஹைட்ரோ</td>\n      <td>haitrao</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6861</th>\n      <td>ஹைட்ரோ</td>\n      <td>hydro</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6862</th>\n      <td>ஹைதர்</td>\n      <td>haithar</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6863</th>\n      <td>ஹைதர்</td>\n      <td>hyder</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>6864 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport keras","metadata":{"id":"B1QeHChSO5b_","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:30:50.809770Z","iopub.execute_input":"2025-05-19T16:30:50.810321Z","iopub.status.idle":"2025-05-19T16:31:04.643488Z","shell.execute_reply.started":"2025-05-19T16:30:50.810297Z","shell.execute_reply":"2025-05-19T16:31:04.642922Z"}},"outputs":[{"name":"stderr","text":"2025-05-19 16:30:52.697082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747672252.912385      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747672252.970124      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"CELL_MAP = {\n    \"RNN\" : keras.layers.SimpleRNN,\n    \"LSTM\" : keras.layers.LSTM,\n    \"GRU\" : keras.layers.GRU\n}","metadata":{"id":"b1urOwUFCB8h","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T16:31:04.644616Z","iopub.execute_input":"2025-05-19T16:31:04.645188Z","iopub.status.idle":"2025-05-19T16:31:04.649014Z","shell.execute_reply.started":"2025-05-19T16:31:04.645164Z","shell.execute_reply":"2025-05-19T16:31:04.648352Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os\nimport random\nimport numpy as np\nimport tensorflow as tf\n\ndef set_seed(seed=42):\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n# Set seed\n\nclass BahdanauAttention(keras.layers.Layer):\n    def __init__(self, units):\n        super().__init__()\n        self.W1 = keras.layers.Dense(units)\n        self.W2 = keras.layers.Dense(units)\n        self.V = keras.layers.Dense(1)\n\n    def call(self, query, values):\n        # query: decoder hidden state at current timestep (bs, hidden)\n        # values: encoder outputs (bs, max_len, hidden)\n        query_with_time_axis = tf.expand_dims(query, 1)  # (bs, 1, hidden)\n        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))  # (bs, max_len, 1)\n        attention_weights = tf.nn.softmax(score, axis=1)  # (bs, max_len, 1)\n        context_vector = attention_weights * values  # (bs, max_len, hidden)\n        context_vector = tf.reduce_sum(context_vector, axis=1)  # (bs, hidden)\n        return context_vector, attention_weights\n\nclass Char2CharModelAttention:\n    def __init__(self, latent_dim=32, hidden_size=32, epochs=10, batch_size=256, dropout=0,\n        cell_type=\"LSTM\", num_encoder_layers=3, num_decoder_layers=3, config=None):\n        # Hyperparameters\n        if config is None:\n            self.latent_dim = latent_dim\n            self.hidden_size = hidden_size\n            self.epochs = epochs\n            self.batch_size = batch_size\n            self.dropout = dropout\n            self.cell_type = cell_type\n            self.num_encoder_layers = num_encoder_layers\n            self.num_decoder_layers = num_decoder_layers\n        else:\n            self.latent_dim = config.latent_dim\n            self.hidden_size = config.hidden_size\n            self.epochs = config.epochs\n            self.batch_size = config.batch_size\n            self.dropout = config.dropout\n            self.cell_type = config.cell_type\n            self.num_encoder_layers = config.num_encoder_layers\n            self.num_decoder_layers = config.num_decoder_layers\n            \n        # Model requirements\n        self.num_encoder_tokens = 0\n        self.num_decoder_tokens = 0\n        self.max_encoder_seq_length = 0\n        self.max_decoder_seq_length = 0\n        self.input_token_index = None\n        self.target_token_index = None\n        self.reverse_input_char_index = None\n        self.reverse_target_char_index = None\n        self.model = None\n        self.encoder_model = None\n        self.decoder_model = None\n\n    def preprocess(self, data, train=False):\n        input_texts = []\n        target_texts = []\n        input_characters = set('_')\n        target_characters = set('_')\n\n        for _, row in data.iterrows():\n            input_text, target_text = row[1], row[0]\n            if not isinstance(input_text, str) or not isinstance(target_text, str):\n                continue\n            target_text = \"\\t\" + target_text + \"\\n\"  # start and end tokens\n            input_texts.append(input_text)\n            target_texts.append(target_text)\n            for char in input_text:\n                input_characters.add(char)\n            for char in target_text:\n                target_characters.add(char)\n\n        if train:\n            input_characters = sorted(list(input_characters))\n            target_characters = sorted(list(target_characters))\n            self.num_encoder_tokens = len(input_characters)\n            self.num_decoder_tokens = len(target_characters)\n            self.max_encoder_seq_length = max(len(txt) for txt in input_texts)\n            self.max_decoder_seq_length = max(len(txt) for txt in target_texts)\n            self.input_token_index = {char: i for i, char in enumerate(input_characters)}\n            self.target_token_index = {char: i for i, char in enumerate(target_characters)}\n            self.reverse_input_char_index = {i: char for char, i in self.input_token_index.items()}\n            self.reverse_target_char_index = {i: char for char, i in self.target_token_index.items()}\n        else:\n            # Use stored values for validation/test\n            input_characters = sorted(self.input_token_index.keys())\n            target_characters = sorted(self.target_token_index.keys())\n\n        encoder_input_data = np.zeros(\n            (len(input_texts), self.max_encoder_seq_length, self.num_encoder_tokens),\n            dtype=\"float32\"\n        )\n        decoder_input_data = np.zeros(\n            (len(input_texts), self.max_decoder_seq_length, self.num_decoder_tokens),\n            dtype=\"float32\"\n        )\n        decoder_target_data = np.zeros(\n            (len(input_texts), self.max_decoder_seq_length, self.num_decoder_tokens),\n            dtype=\"float32\"\n        )\n\n        for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n            for t, char in enumerate(input_text):\n                encoder_input_data[i, t, self.input_token_index[char]] = 1.0\n            encoder_input_data[i, t + 1 :, self.input_token_index[\"_\"]] = 1.0\n            for t, char in enumerate(target_text):\n                decoder_input_data[i, t, self.target_token_index[char]] = 1.0\n                if t > 0:\n                    decoder_target_data[i, t - 1, self.target_token_index[char]] = 1.0\n            decoder_input_data[i, t + 1 :, self.target_token_index[\"_\"]] = 1.0\n            decoder_target_data[i, t:, self.target_token_index[\"_\"]] = 1.0\n\n        if train:\n            print(f\"Number of samples: {len(input_texts)}\")\n            print(f\"Number of unique input tokens: {self.num_encoder_tokens}\")\n            print(f\"Number of unique output tokens: {self.num_decoder_tokens}\")\n            print(f\"Max sequence length for inputs: {self.max_encoder_seq_length}\")\n            print(f\"Max sequence length for outputs: {self.max_decoder_seq_length}\")\n\n        return input_characters, target_characters, encoder_input_data, decoder_input_data, decoder_target_data\n\n    def train(self, train_data, dev_data):\n        _, _, train_encoder_input_data, train_decoder_input_data, train_decoder_target_data = self.preprocess(train_data, train=True)\n        _, _, dev_encoder_input_data, dev_decoder_input_data, dev_decoder_target_data = self.preprocess(dev_data)\n\n        set_seed(42)\n        # Encoder\n        encoder_inputs = keras.Input(shape=(None, self.num_encoder_tokens))\n        encoder_outputs = encoder_inputs\n        for i in range(self.num_encoder_layers):\n          if i==0:\n            embedding_len = self.latent_dim\n          else:\n            embedding_len = self.hidden_size\n          encoder = CELL_MAP[self.cell_type](embedding_len, name=f\"encoder_{i}\", return_sequences=True, return_state=True, dropout=self.dropout)\n          #cell state is s_t, hidden state is h_t\n          encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n        encoder_states = [state_h, state_c]\n\n        # Decoder inputs\n        decoder_inputs = keras.Input(shape=(None, self.num_decoder_tokens))\n        # Create separate attention layers (done in __init__ or train)\n        self.attention_layers = [BahdanauAttention(self.hidden_size) for i in range(self.num_decoder_layers)]\n\n        decoder_outputs = decoder_inputs\n        for i in range(self.num_decoder_layers):\n          decoder_cell = CELL_MAP[self.cell_type](self.hidden_size, name=f\"decoder_{i}\", return_sequences=True, return_state=True, dropout=self.dropout)\n\n          # Attention layer\n          all_outputs = []\n          inputs = decoder_outputs\n          states = encoder_states\n\n          # Loop over decoder time steps\n          for t in range(self.max_decoder_seq_length):\n              decoder_input_t = keras.layers.Lambda(lambda x: x[:, t:t+1, :])(inputs)\n              context_vector, _ = self.attention_layers[i](states[0], encoder_outputs)  # states[0] = hidden state h_t\n              context_vector = keras.layers.Lambda(lambda x: tf.expand_dims(x, 1))(context_vector)\n              decoder_combined_input = keras.layers.Concatenate(axis=-1)([decoder_input_t, context_vector])\n              decoder_output, state_h, state_c = decoder_cell(decoder_combined_input, initial_state=states)\n              states = [state_h, state_c]\n              all_outputs.append(decoder_output)\n\n          decoder_outputs = keras.layers.Concatenate(axis=1)(all_outputs)\n\n        decoder_dense = keras.layers.Dense(self.num_decoder_tokens, name=\"dense\", activation=\"softmax\")\n        decoder_outputs = decoder_dense(decoder_outputs)\n\n        model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n        model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n        model.fit(\n            [train_encoder_input_data, train_decoder_input_data],\n            train_decoder_target_data,\n            batch_size=self.batch_size,\n            epochs=self.epochs,\n            validation_data=([dev_encoder_input_data, dev_decoder_input_data], dev_decoder_target_data),\n        )\n        self.model = model\n        self.predictor_setup()\n        _, val_seq_acc = self.evaluate(dev_data.loc[:, 0], dev_data.loc[:, 1])\n        print(f\"Val_seq_acc: {val_seq_acc}\")\n\n    def predictor_setup(self):\n        model = self.model\n        # Encoder model\n        encoder_inputs = model.input[0]  # input_1\n        final_encoder_layer = self.model.get_layer(f\"encoder_{self.num_encoder_layers-1}\")\n        encoder_outputs, state_h_enc, state_c_enc = final_encoder_layer.output  # lstm_1\n        self.encoder_model = keras.Model(encoder_inputs, [encoder_outputs, state_h_enc, state_c_enc])\n\n        decoder_inputs = model.input[1]  # input_2\n        decoder_states_inputs = []\n\n        for i in range(self.num_decoder_layers):\n            decoder_state_input_h = keras.layers.Input(shape=(self.hidden_size,), name=f\"decoder_state_input_h_{i}\")\n            decoder_state_input_c = keras.layers.Input(shape=(self.hidden_size,), name=f\"decoder_state_input_c_{i}\")\n            encoder_outputs_input = keras.Input(shape=(None, self.latent_dim), name=f\"encoder_outputs_input_{i}\")\n            decoder_states_inputs += [decoder_state_input_h, decoder_state_input_c, encoder_outputs_input]\n\n        x = decoder_inputs\n        decoder_states_outputs = []\n        attention_weights_all = []\n\n        for i in range(self.num_decoder_layers):\n            decoder_cell = model.get_layer(f\"decoder_{i}\")\n            state_input_h = decoder_states_inputs[3*i]\n            state_input_c = decoder_states_inputs[3*i + 1]\n            encoder_outputs_input = decoder_states_inputs[3*i + 2]\n            context_vector, attention_weights = self.attention_layers[i](state_input_h, encoder_outputs_input)\n            context_vector = keras.layers.Lambda(lambda x: tf.expand_dims(x, 1))(context_vector)\n            combined_input = keras.layers.Concatenate(axis=-1)([x, context_vector])\n            x, state_h, state_c = decoder_cell(combined_input, initial_state=[state_input_h, state_input_c])\n            decoder_states_outputs += [state_h, state_c]\n            attention_weights_all += [attention_weights]\n\n        decoder_dense = model.get_layer(\"dense\")\n        decoder_outputs = decoder_dense(x)\n\n        decoder_model = keras.Model(\n            [decoder_inputs] + decoder_states_inputs,\n            [decoder_outputs]+ decoder_states_outputs +  attention_weights_all\n        )\n\n        self.decoder_model = decoder_model\n\n\n    def decode(self, words=None):\n        batch_size = len(words)\n        encoder_input_data = np.zeros((batch_size, self.max_encoder_seq_length, self.num_encoder_tokens), dtype=\"float32\")\n\n        for i, row in enumerate(words.itertuples(index=False)):\n            input_text = row[0]\n            for t, char in enumerate(input_text):\n                encoder_input_data[i, t, self.input_token_index[char]] = 1.0\n            encoder_input_data[i, t + 1 :, self.input_token_index[\"_\"]] = 1.0\n\n        encoder_outputs, state_h, state_c = self.encoder_model.predict(encoder_input_data, verbose=0)\n\n        target_seq = np.zeros((batch_size, 1, self.num_decoder_tokens))\n        target_seq[:, 0, self.target_token_index[\"\\t\"]] = 1.0  # start token\n\n        decoded_words = [\"\"] * batch_size\n        stop_conditions = [False] * batch_size\n\n        states_value_start = [state_h, state_c, encoder_outputs]*self.num_decoder_layers\n        states_value = states_value_start\n        while not all(stop_conditions):\n            outputs_all = self.decoder_model.predict(\n                [target_seq]+states_value,\n                verbose = 0\n            )\n            output_tokens = outputs_all[0]\n            states_value = outputs_all[1:-self.num_decoder_layers]\n            target_seq = np.zeros((batch_size, 1, self.num_decoder_tokens))\n\n            for i in range(batch_size):\n                sampled_token_index = np.argmax(output_tokens[i, -1, :])\n                sampled_char = self.reverse_target_char_index[sampled_token_index]\n                if sampled_char != \"\\n\":\n                    decoded_words[i] += sampled_char\n                if sampled_char == \"\\n\" or len(decoded_words[i]) > self.max_decoder_seq_length:\n                    stop_conditions[i] = True\n                target_seq[i, 0, sampled_token_index] = 1.0\n\n            next_states = states_value\n            states_value = []\n            for i in range(self.num_decoder_layers):\n                h = next_states[2 * i]\n                c = next_states[2 * i + 1]\n                e = encoder_outputs\n                states_value += [h, c, e]\n\n        return decoded_words\n\n    def evaluate(self, native_words, romanized_words, batch_size=256):\n        assert len(native_words) == len(romanized_words)\n        start = 0\n        total = len(native_words)\n        decoded_words = []\n        while start < total:\n            end = min(start + batch_size, total)\n            batch_df = pd.DataFrame(romanized_words.iloc[start:end])\n            decoded_words += self.decode(batch_df)\n            start += batch_size\n        out = pd.DataFrame({\"Romanized\": romanized_words, \"Native\": native_words, \"Predicted\": decoded_words})\n        out[\"Predicted\"] = out[\"Predicted\"].str.replace(\"_\", \"\")\n        accuracy = (out[\"Native\"] == out[\"Predicted\"]).mean()\n        return out, accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:54:23.371306Z","iopub.execute_input":"2025-05-19T18:54:23.371560Z","iopub.status.idle":"2025-05-19T18:54:23.406297Z","shell.execute_reply.started":"2025-05-19T18:54:23.371544Z","shell.execute_reply":"2025-05-19T18:54:23.405647Z"},"id":"_EW6WU7zwT8R"},"outputs":[],"execution_count":49},{"cell_type":"code","source":"agent = Char2CharModelAttention()\nagent.train(train_data, dev_data)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CXb9GQb5jJy","outputId":"acedca2d-494b-4f6d-d8fe-25cfcfd580c4","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:54:28.422850Z","iopub.execute_input":"2025-05-19T18:54:28.423137Z","iopub.status.idle":"2025-05-19T19:04:47.944988Z","shell.execute_reply.started":"2025-05-19T18:54:28.423116Z","shell.execute_reply":"2025-05-19T19:04:47.944248Z"}},"outputs":[{"name":"stdout","text":"Number of samples: 68215\nNumber of unique input tokens: 27\nNumber of unique output tokens: 49\nMax sequence length for inputs: 30\nMax sequence length for outputs: 28\nEpoch 1/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 216ms/step - accuracy: 0.6516 - loss: 1.7214 - val_accuracy: 0.7056 - val_loss: 1.0797\nEpoch 2/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 129ms/step - accuracy: 0.6911 - loss: 1.1026 - val_accuracy: 0.7186 - val_loss: 0.9778\nEpoch 3/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 128ms/step - accuracy: 0.6961 - loss: 1.0589 - val_accuracy: 0.7161 - val_loss: 0.9797\nEpoch 4/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 129ms/step - accuracy: 0.6979 - loss: 1.0464 - val_accuracy: 0.7189 - val_loss: 0.9619\nEpoch 5/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 129ms/step - accuracy: 0.6989 - loss: 1.0381 - val_accuracy: 0.7219 - val_loss: 0.9502\nEpoch 6/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 128ms/step - accuracy: 0.6999 - loss: 1.0318 - val_accuracy: 0.7230 - val_loss: 0.9461\nEpoch 7/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 129ms/step - accuracy: 0.7008 - loss: 1.0264 - val_accuracy: 0.7240 - val_loss: 0.9414\nEpoch 8/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 129ms/step - accuracy: 0.7023 - loss: 1.0172 - val_accuracy: 0.7254 - val_loss: 0.9280\nEpoch 9/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 129ms/step - accuracy: 0.7043 - loss: 1.0028 - val_accuracy: 0.7302 - val_loss: 0.9168\nEpoch 10/10\n\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 128ms/step - accuracy: 0.7067 - loss: 0.9908 - val_accuracy: 0.7314 - val_loss: 0.9071\nVal_seq_acc: 0.0\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"# Hyperparameter sweep","metadata":{}},{"cell_type":"code","source":"sweep_config = {\n    'method': 'bayes'\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"project = 'DA6401_A3'\nentity = 'jayagowtham-indian-institute-of-technology-madras'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metric = {\n    'name': 'val_acc',\n    'goal': 'maximize'\n    }\n\nsweep_config['metric'] = metric","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_config['name'] = 'attn_finest_sweep'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"parameters_dict = {\n    'latent_dim' : {\n        'values': [128, 256, 512]\n        },\n    'hidden_size' : {\n        'values': [128, 256, 512]\n        },\n    'epochs': {\n        'values': [5, 10, 20]\n        },\n    'batch_size': {\n        'values': [64, 128, 256]\n        },\n    'dropout': {\n        'values': [0, 0.3, 0.5]\n        },\n    'num_encoder_layers': {\n        'values': [1, 2, 3]\n        },\n    'num_decoder_layers': {\n        'values': [1, 2, 3]\n        },\n\n    }\n\nsweep_config['parameters'] = parameters_dict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sweep_id = wandb.sweep(project=project, entity=entity, sweep=sweep_config)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\n\nn_epochs = 10\ndef sweep_train():\n    run = wandb.init()\n    config = wandb.config\n    tr = agent(config)\n    tr.train(train_data, val_data)\n    gc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.agent(sweep_id, sweep_train, entity=entity, project=project, count=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Best model visualization","metadata":{}},{"cell_type":"code","source":"best_agent = Char2CharModelAttention(latent_dim=32, hidden_size=32, epochs=100, batch_size=256, dropout=0,\n        cell_type=\"LSTM\", num_encoder_layers=3, num_decoder_layers=3, config=None)\nbest_agent.train(train_data, dev_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef character_confusion_matrix(true_seqs, pred_seqs, char_list):\n    # Remove special tokens and pad predictions\n    cleaned_true = []\n    cleaned_pred = []\n    \n    for t, p in zip(true_seqs, pred_seqs):\n        t = t.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n        p = p.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n        max_len = max(len(t), len(p))\n        t = t.ljust(max_len, \"_\")  # pad with _\n        p = p.ljust(max_len, \"_\")\n        cleaned_true.extend(list(t))\n        cleaned_pred.extend(list(p))\n    \n    # Create character index mapping\n    char_to_index = {ch: i for i, ch in enumerate(sorted(set(char_list)))}\n    \n    y_true = [char_to_index[ch] for ch in cleaned_true]\n    y_pred = [char_to_index[ch] for ch in cleaned_pred]\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred, labels=range(len(char_to_index)))\n\n    # Display\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=sorted(char_list))\n    fig, ax = plt.subplots(figsize=(12, 12))\n    disp.plot(ax=ax, cmap=\"Blues\", xticks_rotation=90)\n    plt.title(\"Character-level Confusion Matrix\")\n    plt.show()\n    \n    return cm\n\nout, _ = model.evaluate(dev_data.iloc[:, 0], dev_data.iloc[:, 1])\ncharacter_list = list(best_agent.target_token_index.keys())  # or reverse_target_char_index.values()\ncm = character_confusion_matrix(out[\"Native\"], out[\"Predicted\"], character_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"td, acc = agent.evaluate(test_data.iloc[:,0], test_data.iloc[:,1])\nacc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T19:04:47.946492Z","iopub.execute_input":"2025-05-19T19:04:47.946765Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"td","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import HTML as html_print\nfrom IPython.display import display\n\ndef cstr(s, color='black'):\n    return f\"<text style='color:#000;background-color:{color};'>{s}</text>\"\n\ndef print_color(t):\n    display(html_print(''.join([cstr(char, color) for char, color in t])))\n\ndef get_clr(value):\n    # Normalize to [0, 1]\n    value = min(max(value, 0), 1)\n    colors = ['#eff7fb', '#d0e6f2', '#a1d0e8', '#85c2e1', '#66b2db',\n              '#4ba3d6', '#2d93d1', '#1785cc', '#0077c7', '#005fa3']\n    index = int(value * (len(colors) - 1))\n    return colors[index]\n\ndef visualize_attention(agent, input_word, layer=0):\n    # Prepare input\n    input_df = pd.DataFrame([input_word])\n    encoder_input_data = np.zeros((1, agent.max_encoder_seq_length, agent.num_encoder_tokens), dtype=\"float32\")\n    for t, char in enumerate(input_word):\n        encoder_input_data[0, t, agent.input_token_index[char]] = 1.0\n    encoder_input_data[0, t+1:, agent.input_token_index[\"_\"]] = 1.0\n\n    # Run encoder\n    encoder_outputs, state_h, state_c = agent.encoder_model.predict(encoder_input_data, verbose=0)\n    states = [state_h, state_c]\n\n    target_seq = np.zeros((1, 1, agent.num_decoder_tokens))\n    target_seq[0, 0, agent.target_token_index[\"\\t\"]] = 1.0\n\n    decoded_word = \"\"\n    attention_history = []\n\n\n    states_value_start = [state_h, state_c, encoder_outputs]*agent.num_decoder_layers\n    states_value = states_value_start\n    while True:\n        outputs_all = agent.decoder_model.predict(\n            [target_seq]+states_value,\n            verbose = 0\n        )\n        output_tokens = outputs_all[0]\n        states_value = outputs_all[1:-agent.num_decoder_layers]\n        attn_weights = outputs_all[-agent.num_decoder_layers:]\n        target_seq = np.zeros((1, 1, agent.num_decoder_tokens))\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = agent.reverse_target_char_index[sampled_token_index]\n        decoded_word += sampled_char\n        if sampled_char == \"\\n\" or len(decoded_word) > agent.max_decoder_seq_length:\n            if sampled_char == \"\\n\":\n                decoded_word = decoded_word[:-1]\n            break\n        weights = attn_weights[layer].squeeze()\n        attention_history.append((sampled_char, weights))\n        target_seq[0, 0, sampled_token_index] = 1.0\n\n        next_states = states_value\n        states_value = []\n        for i in range(agent.num_decoder_layers):\n            h = next_states[2 * i]\n            c = next_states[2 * i + 1]\n            e = encoder_outputs\n            states_value += [h, c, e]\n\n    # Visualize\n    input_chars = list(input_word)\n    for char, weights in attention_history:\n        text_colours = [(input_chars[i], get_clr(weights[i])) for i in range(len(input_chars))]\n        print(f\"Decoder step predicting: {char}\")\n        print_color(text_colours)\n","metadata":{"id":"nJdAzqFx5JPv","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:33:28.609183Z","iopub.execute_input":"2025-05-19T18:33:28.609447Z","iopub.status.idle":"2025-05-19T18:33:28.620623Z","shell.execute_reply.started":"2025-05-19T18:33:28.609429Z","shell.execute_reply":"2025-05-19T18:33:28.620016Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"visualize_attention(agent, \"namaste\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"id":"xaSY1v6M_gdA","outputId":"76942691-3128-480d-e48e-8c3212a0c379","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T18:33:30.698353Z","iopub.execute_input":"2025-05-19T18:33:30.699045Z","iopub.status.idle":"2025-05-19T18:33:34.442470Z","shell.execute_reply.started":"2025-05-19T18:33:30.699024Z","shell.execute_reply":"2025-05-19T18:33:34.441781Z"}},"outputs":[{"name":"stdout","text":"Decoder step predicting: ஸ\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: க\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}},{"name":"stdout","text":"Decoder step predicting: _\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<text style='color:#000;background-color:#eff7fb;'>n</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>m</text><text style='color:#000;background-color:#eff7fb;'>a</text><text style='color:#000;background-color:#eff7fb;'>s</text><text style='color:#000;background-color:#eff7fb;'>t</text><text style='color:#000;background-color:#eff7fb;'>e</text>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# attn_agent = Char2CharModelAttentionGPT()\n# attn_agent.train(train_data, dev_data)","metadata":{"id":"k6EIpECO-28a","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:49:22.060254Z","iopub.execute_input":"2025-05-19T12:49:22.060548Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# td,acc = attn_agent.evaluate(test_data.iloc[:,0], test_data.iloc[:,1])\n# acc","metadata":{"id":"vlE4I-7Mw1zH","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:46:10.240116Z","iopub.status.idle":"2025-05-19T12:46:10.240367Z","shell.execute_reply.started":"2025-05-19T12:46:10.240228Z","shell.execute_reply":"2025-05-19T12:46:10.240238Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# np.unique([len(td[\"Predicted\"][i]) for i in range(td.shape[0])])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:46:10.241558Z","iopub.status.idle":"2025-05-19T12:46:10.241841Z","shell.execute_reply.started":"2025-05-19T12:46:10.241730Z","shell.execute_reply":"2025-05-19T12:46:10.241742Z"},"id":"t_7VXG_zwT8T"},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# td.iloc[10:20,:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T12:46:10.242912Z","iopub.status.idle":"2025-05-19T12:46:10.243220Z","shell.execute_reply.started":"2025-05-19T12:46:10.243067Z","shell.execute_reply":"2025-05-19T12:46:10.243081Z"},"id":"c3mpPwiqwT8U"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# username = \"JG-0212\"\n# token = \"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\"\n# remote_url = f\"https://{username}:{token}@github.com/{username}/DA6401_A3.git\"","metadata":{"id":"AwTnS8UlkCHO"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# !git push remote_url main","metadata":{"id":"9LOiPkMZkX-x"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# remote_url","metadata":{"id":"Mq0PIpPckd9U"},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# !git config --global user.email \"jpsai6594@gmail.com\"\n# !git config --global user.name \"JG-0212\"","metadata":{"id":"ucxE_PHZikvT"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# !git push origin main","metadata":{"id":"OAFCPPNKPBTr"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"","metadata":{"id":"VZNaoBNWNZZ3"},"outputs":[],"execution_count":17}]}